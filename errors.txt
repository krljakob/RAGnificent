uv!
Using CPython 3.12.10
Creating virtual environment at: .venv
Activate with: source .venv/bin/activate.fish
Resolved 76 packages in 49ms
Installed 76 packages in 50ms
 + annotated-types==0.7.0
 + anyio==4.9.0
 + argparse==1.4.0
 + beautifulsoup4==4.13.4
 + bleach==6.2.0
 + certifi==2025.4.26
 + charset-normalizer==3.4.2
 + click==8.2.1
 + contourpy==1.3.2
 + cycler==0.12.1
 + distro==1.9.0
 + fastapi==0.115.12
 + fonttools==4.58.2
 + grpcio==1.72.1
 + h11==0.16.0
 + h2==4.2.0
 + hpack==4.1.0
 + httpcore==1.0.9
 + httpx==0.28.1
 + hyperframe==6.1.0
 + idna==3.10
 + iniconfig==2.1.0
 + jiter==0.10.0
 + joblib==1.5.1
 + kiwisolver==1.4.8
 + markdownify==1.1.0
 + matplotlib==3.10.3
 + maturin==1.8.6
 + mypy==1.16.0
 + mypy-extensions==1.1.0
 + numpy==2.2.6
 + openai==1.84.0
 + packaging==25.0
 + pandas==2.3.0
 + patchelf==0.17.2.2
 + pathlib==1.0.1
 + pathspec==0.12.1
 + pillow==11.2.1
 + pluggy==1.6.0
 + portalocker==2.10.1
 + protobuf==6.31.1
 + psutil==7.0.0
 + py-cpuinfo==9.0.0
 + pydantic==2.11.5
 + pydantic-core==2.33.2
 + pydantic-settings==2.9.1
 + pygments==2.19.1
 + pyparsing==3.2.3
 + pytest==8.4.0
 + pytest-benchmark==5.1.0
 + pytest-mock==3.14.1
 + python-dateutil==2.9.0.post0
 + python-dotenv==1.1.0
 + pytz==2025.2
 + pyyaml==6.0.2
 + qdrant-client==1.14.2
 + requests==2.32.3
 + responses==0.25.7
 + scikit-learn==1.7.0
 + scipy==1.15.3
 + seaborn==0.13.2
 + six==1.17.0
 + sniffio==1.3.1
 + soupsieve==2.7
 + starlette==0.46.2
 + threadpoolctl==3.6.0
 + tqdm==4.67.1
 + types-beautifulsoup4==4.12.0.20250516
 + types-html5lib==1.1.11.20250516
 + types-requests==2.32.0.20250602
 + typing-extensions==4.14.0
 + typing-inspection==0.4.1
 + tzdata==2025.2
 + urllib3==2.4.0
 + uvicorn==0.34.3
 + webencodings==0.5.1
‚ùØ cargo build --release && maturin develop --release && maturin build --release && pytest .
   Compiling pyo3-build-config v0.24.1
   Compiling pyo3-macros-backend v0.24.1
   Compiling pyo3-ffi v0.24.1
   Compiling pyo3 v0.24.1
   Compiling pyo3-macros v0.24.1
   Compiling RAGnificent v1.0.0 (/home/sistr/Projects/RAGnificent)
    Finished `release` profile [optimized] target(s) in 6.78s
üì¶ Including license file "/home/sistr/Projects/RAGnificent/LICENSE"
üçπ Building a mixed python/rust project
üîó Found pyo3 bindings
üêç Found CPython 3.12 at /home/sistr/Projects/RAGnificent/.venv/bin/python
üì° Using build options features from pyproject.toml
Resolved 66 packages in 39ms
Installed 31 packages in 114ms
 + filelock==3.18.0
 + fsspec==2025.5.1
 + hf-xet==1.1.3
 + huggingface-hub==0.32.4
 + jinja2==3.1.6
 + markupsafe==3.0.2
 + mpmath==1.3.0
 + networkx==3.5
 + nvidia-cublas-cu12==12.6.4.1
 + nvidia-cuda-cupti-cu12==12.6.80
 + nvidia-cuda-nvrtc-cu12==12.6.77
 + nvidia-cuda-runtime-cu12==12.6.77
 + nvidia-cudnn-cu12==9.5.1.17
 + nvidia-cufft-cu12==11.3.0.4
 + nvidia-cufile-cu12==1.11.1.6
 + nvidia-curand-cu12==10.3.7.77
 + nvidia-cusolver-cu12==11.7.1.2
 + nvidia-cusparse-cu12==12.5.4.2
 + nvidia-cusparselt-cu12==0.6.3
 + nvidia-nccl-cu12==2.26.2
 + nvidia-nvjitlink-cu12==12.6.85
 + nvidia-nvtx-cu12==12.6.77
 + regex==2024.11.6
 + safetensors==0.5.3
 + sentence-transformers==4.1.0
 + setuptools==80.9.0
 + sympy==1.14.0
 + tokenizers==0.21.1
 + torch==2.7.1
 + transformers==4.51.3
 + triton==3.3.1
   Compiling pyo3-build-config v0.24.1
   Compiling pyo3-macros-backend v0.24.1
   Compiling pyo3-ffi v0.24.1
   Compiling pyo3 v0.24.1
   Compiling pyo3-macros v0.24.1
   Compiling RAGnificent v1.0.0 (/home/sistr/Projects/RAGnificent)
    Finished `release` profile [optimized] target(s) in 22.09s
üì¶ Built wheel for CPython 3.12 to /tmp/.tmpvYvHmW/RAGnificent-1.0.0-cp312-cp312-linux_x86_64.whl
‚úèÔ∏è Setting installed package as editable
üõ† Installed RAGnificent-1.0.0
üì¶ Including license file "/home/sistr/Projects/RAGnificent/LICENSE"
üçπ Building a mixed python/rust project
üîó Found pyo3 bindings
üêç Found CPython 3.12 at /home/sistr/Projects/RAGnificent/.venv/bin/python
üì° Using build options features from pyproject.toml
    Finished `release` profile [optimized] target(s) in 0.06s
üñ®  Copied external shared libraries to package RAGnificent.libs directory:
    /usr/lib/x86_64-linux-gnu/libssl.so.3
    /usr/lib/x86_64-linux-gnu/libcrypto.so.3
    /usr/lib/x86_64-linux-gnu/libzstd.so.1.5.6
üì¶ Built wheel for CPython 3.12 to /home/sistr/Projects/RAGnificent/target/wheels/RAGnificent-1.0.0-cp312-cp312-manylinux_2_34_x86_64.whl
=================================================================================================================== test session starts ====================================================================================================================
platform linux -- Python 3.12.10, pytest-8.4.0, pluggy-1.6.0
benchmark: 5.1.0 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)
rootdir: /home/sistr/Projects/RAGnificent
configfile: pyproject.toml
plugins: anyio-4.9.0, mock-3.14.1, benchmark-5.1.0
collected 121 items

tests/benchmarks/test_performance.py .FFFF                                                                                                                                                                                                           [  4%]
tests/integration/test_rag_integration.py F.                                                                                                                                                                                                         [  5%]
tests/rust/test_python_bindings.py ....                                                                                                                                                                                                              [  9%]
tests/test_benchmarks.py .........                                                                                                                                                                                                                   [ 16%]
tests/unit/test_chunk_utils.py ....                                                                                                                                                                                                                  [ 19%]
tests/unit/test_chunk_utils_edge_cases.py .............                                                                                                                                                                                              [ 30%]
tests/unit/test_config.py F....                                                                                                                                                                                                                      [ 34%]
tests/unit/test_embedding_edge_cases.py ..                                                                                                                                                                                                           [ 36%]
tests/unit/test_embedding_edge_cases_part2.py F.FFFF                                                                                                                                                                                                 [ 41%]
tests/unit/test_embedding_service.py .s                                                                                                                                                                                                              [ 42%]
tests/unit/test_main.py ........                                                                                                                                                                                                                     [ 49%]
tests/unit/test_nested_header_chunking.py ...                                                                                                                                                                                                        [ 52%]
tests/unit/test_nested_headers/fixed_test.py F.                                                                                                                                                                                                      [ 53%]
tests/unit/test_nested_headers/test_improved_chunking.py F.F                                                                                                                                                                                         [ 56%]
tests/unit/test_nested_headers/test_nested_header_chunking.py F.                                                                                                                                                                                     [ 57%]
tests/unit/test_nested_headers/test_with_explicit_headers.py ..                                                                                                                                                                                      [ 59%]
tests/unit/test_pipeline_edge_cases.py F..FF...                                                                                                                                                                                                      [ 66%]
tests/unit/test_pipeline_edge_cases_part2.py .......F.                                                                                                                                                                                               [ 73%]
tests/unit/test_scraper_error_handling.py ss.s..F.F                                                                                                                                                                                                  [ 80%]
tests/unit/test_search_edge_cases.py F.                                                                                                                                                                                                              [ 82%]
tests/unit/test_search_edge_cases_part2.py ......                                                                                                                                                                                                    [ 87%]
tests/unit/test_sitemap_utils.py ......                                                                                                                                                                                                              [ 92%]
tests/unit/test_sitemap_utils_edge_cases.py .s.ss...s                                                                                                                                                                                                [100%]

========================================================================================================================= FAILURES =========================================================================================================================
________________________________________________________________________________________________________________ test_throttler_performance ________________________________________________________________________________________________________________

    def test_throttler_performance():
        """Benchmark the performance of the RequestThrottler."""
        with PerformanceTimer("Throttler initialization (default)"):
            throttler = RequestThrottler()

        with PerformanceTimer("Throttler with domain limits"):
            domain_limits = {
                "example.com": 2.0,
                "test.com": 0.5,
                "*.python.org": 5.0,
            }
            throttler = RequestThrottler(
                requests_per_second=1.0,
                domain_specific_limits=domain_limits,
                max_workers=20,
                adaptive_throttling=True,
            )

        with PerformanceTimer("Throttle (10 requests, same domain)"):
            for i in range(10):
                throttler.throttle("https://example.com/page")

        with PerformanceTimer("Throttle (10 requests, different domains)"):
            domains = ["example.com", "test.com", "python.org", "docs.python.org"]
            for i in range(10):
                domain = domains[i % len(domains)]
                throttler.throttle(f"https://{domain}/page")

        def mock_request(url):
            time.sleep(0.05)  # Simulate network delay
            return type("Response", (), {"status_code": 200})

        with PerformanceTimer("Execute (5 requests)"):
            for i in range(5):
>               throttler.execute(mock_request, f"https://example.com/page{i}")

tests/benchmarks/test_performance.py:336:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <RAGnificent.core.throttle.RequestThrottler object at 0x7fe4c1f484a0>, func = <function test_throttler_performance.<locals>.mock_request at 0x7fe4c1fa53a0>, url = 'https://example.com/page0', args = (), kwargs = {}, domain = 'example.com'
retries = 3, start_time = 1749300750.869302, response_time = 3.910064697265625e-05, retry_delay = 8.0

    def execute(self, func: Callable, url: str, *args, **kwargs) -> Any:
        """
        Execute a function with throttling and retry logic.

        Args:
            func: Function to execute
            url: URL being requested
            *args: Arguments to pass to the function
            **kwargs: Keyword arguments to pass to the function

        Returns:
            Result of the function
        """
        domain = self._extract_domain(url)
        retries = 0

        while retries <= self.max_retries:
            self.throttle(url)
            start_time = time.time()

            try:
>               result = func(*args, **kwargs)
                         ^^^^^^^^^^^^^^^^^^^^^
E               TypeError: test_throttler_performance.<locals>.mock_request() missing 1 required positional argument: 'url'

RAGnificent/core/throttle.py:230: TypeError
-------------------------------------------------------------------------------------------------------------------- Captured log call ---------------------------------------------------------------------------------------------------------------------
WARNING  request_throttler:throttle.py:254 Request to https://example.com/page0 failed with TypeError: test_throttler_performance.<locals>.mock_request() missing 1 required positional argument: 'url'. Retrying in 2.00s (1/3)
WARNING  request_throttler:throttle.py:190 Domain example.com experiencing errors (2 consecutive). Backing off for 4.94s
WARNING  request_throttler:throttle.py:254 Request to https://example.com/page0 failed with TypeError: test_throttler_performance.<locals>.mock_request() missing 1 required positional argument: 'url'. Retrying in 4.00s (2/3)
WARNING  request_throttler:throttle.py:190 Domain example.com experiencing errors (3 consecutive). Backing off for 10.68s
WARNING  request_throttler:throttle.py:254 Request to https://example.com/page0 failed with TypeError: test_throttler_performance.<locals>.mock_request() missing 1 required positional argument: 'url'. Retrying in 8.00s (3/3)
WARNING  request_throttler:throttle.py:190 Domain example.com experiencing errors (4 consecutive). Backing off for 18.44s
ERROR    request_throttler:throttle.py:261 Request to https://example.com/page0 failed after 3 retries: test_throttler_performance.<locals>.mock_request() missing 1 required positional argument: 'url'
_________________________________________________________________________________________________________________ test_chunker_performance _________________________________________________________________________________________________________________

    def test_chunker_performance():
        """Benchmark the performance of the ContentChunker."""
        small_content = (
            "# Heading 1\nThis is a paragraph.\n## Heading 2\nAnother paragraph."
        )
        medium_content = "\n".join(
            [
                f"# Heading {i}\nParagraph {i}.\n## Subheading {i}.1\nMore text.\n### Subheading {i}.1.1\nEven more text."
                for i in range(1, 11)
            ]
        )
        large_content = "\n".join(
            [
                f"# Heading {i}\nParagraph {i}.\n## Subheading {i}.1\nMore text.\n### Subheading {i}.1.1\nEven more text."
                for i in range(1, 101)
            ]
        )

        for chunk_size, chunk_overlap in [(200, 50), (500, 100), (1000, 200)]:
            with PerformanceTimer(
                f"Chunker initialization (size={chunk_size}, overlap={chunk_overlap})"
            ):
                chunker = ContentChunker(chunk_size, chunk_overlap)

            with PerformanceTimer(f"Chunking small content (size={chunk_size})"):
>               small_chunks = chunker.create_chunks_from_markdown(small_content)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E               TypeError: ContentChunker.create_chunks_from_markdown() missing 1 required positional argument: 'source_url'

tests/benchmarks/test_performance.py:373: TypeError
________________________________________________________________________________________________________________ test_pipeline_performance _________________________________________________________________________________________________________________

test_documents = [{'content': 'Python is a programming language that lets you work quickly and integrate systems more effectively.', 't...fic topic.', 'timestamp': '2023-01-01T00:00:00Z', 'title': 'Python HOWTOs', 'url': 'https://docs.python.org/3/howto/'}]
test_chunks = [{'chunk_id': '1', 'content': 'Python is a programming language that lets you work quickly.', 'embedding': [0.1, 0.1, ...ctionality.', 'embedding': [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, ...], 'heading_path': ['Python Standard Library'], ...}, ...]
mock_embedding_service = <test_performance.mock_embedding_service.<locals>.MockEmbeddingService object at 0x7fe4c1f48ec0>, mock_vector_store = <test_performance.mock_vector_store.<locals>.MockVectorStore object at 0x7fe4c1f48650>

    def test_pipeline_performance(
        test_documents, test_chunks, mock_embedding_service, mock_vector_store
    ):
        """Benchmark the performance of the RAG Pipeline."""
        with PerformanceTimer("Pipeline initialization"):
            pipeline = Pipeline(
                collection_name="benchmark_collection",
                embedding_model_type="sentence_transformer",
                embedding_model_name="all-MiniLM-L6-v2",
                chunk_size=500,
                chunk_overlap=100,
                requests_per_second=5.0,
                cache_enabled=True,
            )
            pipeline.embedding_service = mock_embedding_service
            pipeline.vector_store = mock_vector_store

        with PerformanceTimer("Pipeline chunking"), MemoryMonitor("Pipeline chunking"):
            chunks = pipeline.chunk_documents(test_documents)
            logger.info(
                f"Created {len(chunks)} chunks from {len(test_documents)} documents"
            )

        with PerformanceTimer("Pipeline embedding"):
            with MemoryMonitor("Pipeline embedding"):
                embedded_chunks = pipeline.embed_chunks(test_chunks)
                logger.info(f"Generated embeddings for {len(embedded_chunks)} chunks")

        with PerformanceTimer("Pipeline storage"), MemoryMonitor("Pipeline storage"):
>           success = pipeline.store_chunks(embedded_chunks)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/benchmarks/test_performance.py:432:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <RAGnificent.rag.pipeline.Pipeline object at 0x7fe4c1f48410>
chunks = [{'chunk_id': '1', 'content': 'Python is a programming language that lets you work quickly.', 'embedding': [0.1, 0.1, ...ctionality.', 'embedding': [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, ...], 'heading_path': ['Python Standard Library'], ...}, ...]
embedding_field = 'embedding', id_field = 'id'

    def store_chunks(
        self,
        chunks: Union[List[Dict[str, Any]], str],
        embedding_field: str = "embedding",
        id_field: str = "id",
    ) -> bool:
        """
        Store chunks in vector database.

        Args:
            chunks: List of chunk dictionaries with embeddings or path to embedded chunks file
            embedding_field: Field name containing the embedding
            id_field: Field name containing the document ID

        Returns:
            Success flag
        """
        # Load chunks from file if path provided
        if isinstance(chunks, str):
            try:
                with open(chunks, "r", encoding="utf-8") as f:
                    chunks = json.load(f)

                # If these are lightweight chunks without embeddings, we need to re-embed them
                if chunks and all(
                    "has_embedding" in chunk and "embedding" not in chunk
                    for chunk in chunks
                ):
                    logger.info("Re-embedding chunks from file")
                    chunk_list = chunks if isinstance(chunks, list) else []
                    chunks = self.embedding_service.embed_chunks(chunk_list)

            except Exception as e:
                logger.error(f"Error loading embedded chunks from {chunks}: {e}")
                return False

        # Ensure we have chunks with embeddings
        chunk_list = chunks if isinstance(chunks, list) else []
        valid_chunks = [chunk for chunk in chunk_list if embedding_field in chunk]

        if not valid_chunks:
            logger.warning("No chunks with embeddings to store")
            return False

        logger.info(f"Storing {len(valid_chunks)} chunks in vector database")

        # Store chunks in vector database
>       return self.vector_store.store_documents(
            valid_chunks, embedding_field=embedding_field, id_field=id_field
        )
E       TypeError: mock_vector_store.<locals>.MockVectorStore.store_documents() got an unexpected keyword argument 'embedding_field'

RAGnificent/rag/pipeline.py:701: TypeError
____________________________________________________________________________________________________________ test_parallel_scraping_performance ____________________________________________________________________________________________________________

test_urls = ['https://www.python.org/', 'https://docs.python.org/3/tutorial/', 'https://docs.python.org/3/library/', 'https://docs.python.org/3/reference/', 'https://docs.python.org/3/howto/']

    def test_parallel_scraping_performance(test_urls):
        """Benchmark the performance of parallel scraping."""
        with PerformanceTimer("Scraper initialization (default)"):
            MarkdownScraper()

        with PerformanceTimer("Scraper with enhanced parallel processing"):
            enhanced_scraper = MarkdownScraper(
                requests_per_second=5.0,
                domain_specific_limits={"python.org": 10.0},
                max_workers=10,
                adaptive_throttling=True,
            )

        def mock_scrape_website(url):
            time.sleep(0.1)  # Simulate network delay
            return f"<html><body><h1>Title for {url}</h1><p>Content for {url}</p></body></html>"

        enhanced_scraper.scrape_website = mock_scrape_website

        with PerformanceTimer("Sequential scraping (5 URLs)"):
            results = []
            for url in test_urls:
                html = enhanced_scraper.scrape_website(url)
                results.append(html)
            logger.info(f"Scraped {len(results)} URLs sequentially")

        with PerformanceTimer("Parallel scraping with sitemap (5 URLs)"):
            original_discover = enhanced_scraper._discover_urls_from_sitemap
            enhanced_scraper._discover_urls_from_sitemap = lambda url: test_urls

            original_process = enhanced_scraper._process_single_url
            enhanced_scraper._process_single_url = lambda url, *args, **kwargs: {
                "url": url,
                "content": f"Content for {url}",
            }

>           results = enhanced_scraper.scrape_by_sitemap(
                "https://example.com/sitemap.xml", limit=5
            )
E           TypeError: MarkdownScraper.scrape_by_sitemap() missing 1 required positional argument: 'output_dir'

tests/benchmarks/test_performance.py:491: TypeError
_______________________________________________________________________________________________________ TestRAGIntegration.test_end_to_end_pipeline ________________________________________________________________________________________________________

self = <tests.integration.test_rag_integration.TestRAGIntegration testMethod=test_end_to_end_pipeline>

    def test_end_to_end_pipeline(self):
        """Test the complete RAG pipeline end-to-end."""
        chunks = self.pipeline.chunk_documents(
            [self.test_document],
            output_file="test_chunks.json",
            strategy=ChunkingStrategy.SEMANTIC,
        )

        self.assertGreater(len(chunks), 0, "Should create chunks from test document")

        embedded_chunks = self.pipeline.embed_chunks(
            chunks, output_file="test_embedded_chunks.json"
        )

        self.assertEqual(len(embedded_chunks), len(chunks), "Should embed all chunks")
        for chunk in embedded_chunks:
            self.assertIn("embedding", chunk, "Each chunk should have an embedding")

        if success := self.pipeline.store_chunks(embedded_chunks):
            results = self.pipeline.search_documents("RAG systems")

>           self.assertGreater(len(results), 0, "Should find results for query")
E           AssertionError: 0 not greater than 0 : Should find results for query

tests/integration/test_rag_integration.py:89: AssertionError
_________________________________________________________________________________________ TestConfigFileSupport.test_app_config_initialization_with_dict_override __________________________________________________________________________________________

self = <tests.unit.test_config.TestConfigFileSupport testMethod=test_app_config_initialization_with_dict_override>

    def test_app_config_initialization_with_dict_override(self):
        """Ensure that AppConfig applies overrides from config_dict"""
        override = {
>           "chunking_strategy": ChunkingStrategy.SENTENCE.value,
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^
            "embedding_model_type": EmbeddingModelType.OPENAI.value,
        }
E       AttributeError: type object 'ChunkingStrategy' has no attribute 'SENTENCE'

tests/unit/test_config.py:35: AttributeError
____________________________________________________________________________________________________ TestEmbeddingEdgeCasesPart2.test_openai_api_error _____________________________________________________________________________________________________
../../.local/share/uv/python/cpython-3.12.10-linux-x86_64-gnu/lib/python3.12/unittest/mock.py:1393: in patched
    with self.decoration_helper(patched,
../../.local/share/uv/python/cpython-3.12.10-linux-x86_64-gnu/lib/python3.12/contextlib.py:137: in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
../../.local/share/uv/python/cpython-3.12.10-linux-x86_64-gnu/lib/python3.12/unittest/mock.py:1375: in decoration_helper
    arg = exit_stack.enter_context(patching)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../.local/share/uv/python/cpython-3.12.10-linux-x86_64-gnu/lib/python3.12/contextlib.py:526: in enter_context
    result = _enter(cm)
             ^^^^^^^^^^
../../.local/share/uv/python/cpython-3.12.10-linux-x86_64-gnu/lib/python3.12/unittest/mock.py:1467: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <unittest.mock._patch object at 0x7fe4c2c76360>

    def get_original(self):
        target = self.getter()
        name = self.attribute

        original = DEFAULT
        local = False

        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True

        if name in _builtins and isinstance(target, ModuleType):
            self.create = True

        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'RAGnificent.rag.embedding' from '/home/sistr/Projects/RAGnificent/RAGnificent/rag/embedding.py'> does not have the attribute 'openai'

../../.local/share/uv/python/cpython-3.12.10-linux-x86_64-gnu/lib/python3.12/unittest/mock.py:1437: AttributeError
___________________________________________________________________________________________________ TestEmbeddingEdgeCasesPart2.test_openai_retry_logic ____________________________________________________________________________________________________
../../.local/share/uv/python/cpython-3.12.10-linux-x86_64-gnu/lib/python3.12/unittest/mock.py:1393: in patched
    with self.decoration_helper(patched,
../../.local/share/uv/python/cpython-3.12.10-linux-x86_64-gnu/lib/python3.12/contextlib.py:137: in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
../../.local/share/uv/python/cpython-3.12.10-linux-x86_64-gnu/lib/python3.12/unittest/mock.py:1375: in decoration_helper
    arg = exit_stack.enter_context(patching)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../.local/share/uv/python/cpython-3.12.10-linux-x86_64-gnu/lib/python3.12/contextlib.py:526: in enter_context
    result = _enter(cm)
             ^^^^^^^^^^
../../.local/share/uv/python/cpython-3.12.10-linux-x86_64-gnu/lib/python3.12/unittest/mock.py:1467: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <unittest.mock._patch object at 0x7fe4c2c76480>

    def get_original(self):
        target = self.getter()
        name = self.attribute

        original = DEFAULT
        local = False

        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True

        if name in _builtins and isinstance(target, ModuleType):
            self.create = True

        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'RAGnificent.rag.embedding' from '/home/sistr/Projects/RAGnificent/RAGnificent/rag/embedding.py'> does not have the attribute 'openai'

../../.local/share/uv/python/cpython-3.12.10-linux-x86_64-gnu/lib/python3.12/unittest/mock.py:1437: AttributeError
__________________________________________________________________________________________ TestEmbeddingEdgeCasesPart2.test_sentence_transformer_embedding_error ___________________________________________________________________________________________
../../.local/share/uv/python/cpython-3.12.10-linux-x86_64-gnu/lib/python3.12/unittest/mock.py:1393: in patched
    with self.decoration_helper(patched,
../../.local/share/uv/python/cpython-3.12.10-linux-x86_64-gnu/lib/python3.12/contextlib.py:137: in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
../../.local/share/uv/python/cpython-3.12.10-linux-x86_64-gnu/lib/python3.12/unittest/mock.py:1375: in decoration_helper
    arg = exit_stack.enter_context(patching)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../.local/share/uv/python/cpython-3.12.10-linux-x86_64-gnu/lib/python3.12/contextlib.py:526: in enter_context
    result = _enter(cm)
             ^^^^^^^^^^
../../.local/share/uv/python/cpython-3.12.10-linux-x86_64-gnu/lib/python3.12/unittest/mock.py:1467: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <unittest.mock._patch object at 0x7fe4c2c76240>

    def get_original(self):
        target = self.getter()
        name = self.attribute

        original = DEFAULT
        local = False

        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True

        if name in _builtins and isinstance(target, ModuleType):
            self.create = True

        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'RAGnificent.rag.embedding' from '/home/sistr/Projects/RAGnificent/RAGnificent/rag/embedding.py'> does not have the attribute 'SentenceTransformer'

../../.local/share/uv/python/cpython-3.12.10-linux-x86_64-gnu/lib/python3.12/unittest/mock.py:1437: AttributeError
____________________________________________________________________________________________ TestEmbeddingEdgeCasesPart2.test_sentence_transformer_import_error ____________________________________________________________________________________________
../../.local/share/uv/python/cpython-3.12.10-linux-x86_64-gnu/lib/python3.12/unittest/mock.py:1393: in patched
    with self.decoration_helper(patched,
../../.local/share/uv/python/cpython-3.12.10-linux-x86_64-gnu/lib/python3.12/contextlib.py:137: in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
../../.local/share/uv/python/cpython-3.12.10-linux-x86_64-gnu/lib/python3.12/unittest/mock.py:1375: in decoration_helper
    arg = exit_stack.enter_context(patching)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../.local/share/uv/python/cpython-3.12.10-linux-x86_64-gnu/lib/python3.12/contextlib.py:526: in enter_context
    result = _enter(cm)
             ^^^^^^^^^^
../../.local/share/uv/python/cpython-3.12.10-linux-x86_64-gnu/lib/python3.12/unittest/mock.py:1467: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <unittest.mock._patch object at 0x7fe4c2c75f40>

    def get_original(self):
        target = self.getter()
        name = self.attribute

        original = DEFAULT
        local = False

        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True

        if name in _builtins and isinstance(target, ModuleType):
            self.create = True

        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'RAGnificent.rag.embedding' from '/home/sistr/Projects/RAGnificent/RAGnificent/rag/embedding.py'> does not have the attribute 'SentenceTransformer'

../../.local/share/uv/python/cpython-3.12.10-linux-x86_64-gnu/lib/python3.12/unittest/mock.py:1437: AttributeError
____________________________________________________________________________________________ TestEmbeddingEdgeCasesPart2.test_sentence_transformer_model_error _____________________________________________________________________________________________
../../.local/share/uv/python/cpython-3.12.10-linux-x86_64-gnu/lib/python3.12/unittest/mock.py:1393: in patched
    with self.decoration_helper(patched,
../../.local/share/uv/python/cpython-3.12.10-linux-x86_64-gnu/lib/python3.12/contextlib.py:137: in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
../../.local/share/uv/python/cpython-3.12.10-linux-x86_64-gnu/lib/python3.12/unittest/mock.py:1375: in decoration_helper
    arg = exit_stack.enter_context(patching)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../.local/share/uv/python/cpython-3.12.10-linux-x86_64-gnu/lib/python3.12/contextlib.py:526: in enter_context
    result = _enter(cm)
             ^^^^^^^^^^
../../.local/share/uv/python/cpython-3.12.10-linux-x86_64-gnu/lib/python3.12/unittest/mock.py:1467: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <unittest.mock._patch object at 0x7fe4c2c76150>

    def get_original(self):
        target = self.getter()
        name = self.attribute

        original = DEFAULT
        local = False

        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True

        if name in _builtins and isinstance(target, ModuleType):
            self.create = True

        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'RAGnificent.rag.embedding' from '/home/sistr/Projects/RAGnificent/RAGnificent/rag/embedding.py'> does not have the attribute 'SentenceTransformer'

../../.local/share/uv/python/cpython-3.12.10-linux-x86_64-gnu/lib/python3.12/unittest/mock.py:1437: AttributeError
___________________________________________________________________________________________________ TestNestedHeaderChunking.test_nested_header_chunking ___________________________________________________________________________________________________

self = <fixed_test.TestNestedHeaderChunking testMethod=test_nested_header_chunking>

    def test_nested_header_chunking(self):
        """Test that nested headers are properly handled in chunking."""
        chunks = self.chunker.create_chunks_from_markdown(
            self.nested_markdown, "https://example.com/test"
        )

        self.assertGreater(len(chunks), 1, "Should create multiple chunks")

        subtopic_1_1_chunks = [
            chunk
            for chunk in chunks
            if "Nested Subtopic 1.1" in chunk.metadata.get("heading_path", "")
        ]

>       self.assertGreater(
            len(subtopic_1_1_chunks), 0, "Should have chunks for Nested Subtopic 1.1"
        )
E       AssertionError: 0 not greater than 0 : Should have chunks for Nested Subtopic 1.1

tests/unit/test_nested_headers/fixed_test.py:57: AssertionError
_______________________________________________________________________________________________ TestImprovedNestedHeaderChunking.test_nested_header_chunking _______________________________________________________________________________________________

self = <test_improved_chunking.TestImprovedNestedHeaderChunking testMethod=test_nested_header_chunking>

    def test_nested_header_chunking(self):
        """Test that nested headers are properly handled in chunking."""
        chunks = self.chunker.create_chunks_from_markdown(
            self.nested_markdown, "https://example.com/test"
        )

        self.assertGreater(len(chunks), 1, "Should create multiple chunks")

        subtopic_1_1_chunks = [
            chunk
            for chunk in chunks
            if "Nested Subtopic 1.1" in chunk.metadata.get("heading_path", "")
        ]

>       self.assertGreater(
            len(subtopic_1_1_chunks), 0, "Should have chunks for Nested Subtopic 1.1"
        )
E       AssertionError: 0 not greater than 0 : Should have chunks for Nested Subtopic 1.1

tests/unit/test_nested_headers/test_improved_chunking.py:79: AssertionError
__________________________________________________________________________________________________ TestImprovedNestedHeaderChunking.test_section_parsing ___________________________________________________________________________________________________

self = <test_improved_chunking.TestImprovedNestedHeaderChunking testMethod=test_section_parsing>

    def test_section_parsing(self):
        """Test that markdown sections are correctly parsed."""
        sections = self.chunker._parse_markdown_sections(self.nested_markdown)

>       self.assertGreaterEqual(len(sections), 5, "Should find at least 5 sections")
E       AssertionError: 1 not greater than or equal to 5 : Should find at least 5 sections

tests/unit/test_nested_headers/test_improved_chunking.py:47: AssertionError
___________________________________________________________________________________________________ TestNestedHeaderChunking.test_nested_header_chunking ___________________________________________________________________________________________________

self = <test_nested_header_chunking.TestNestedHeaderChunking testMethod=test_nested_header_chunking>

    def test_nested_header_chunking(self):
        """Test that nested headers are properly handled in chunking."""
        chunks = self.chunker.create_chunks_from_markdown(
            self.nested_markdown, "https://example.com/test"
        )

        self.assertGreater(len(chunks), 1, "Should create multiple chunks")

        subtopic_1_1_chunks = [
            chunk
            for chunk in chunks
            if "Nested Subtopic 1.1" in chunk.metadata["heading_path"]
        ]

>       self.assertGreater(
            len(subtopic_1_1_chunks), 0, "Should have chunks for Nested Subtopic 1.1"
        )
E       AssertionError: 0 not greater than 0 : Should have chunks for Nested Subtopic 1.1

tests/unit/test_nested_headers/test_nested_header_chunking.py:58: AssertionError
_______________________________________________________________________________________________________ TestPipelineEdgeCases.test_embedding_failure _______________________________________________________________________________________________________

self = <tests.unit.test_pipeline_edge_cases.TestPipelineEdgeCases testMethod=test_embedding_failure>, mock_get_embedding = <MagicMock name='get_embedding_service' id='140615441326800'>

    @mock.patch("RAGnificent.rag.embedding.get_embedding_service")
    def test_embedding_failure(self, mock_get_embedding):
        """Test handling of embedding failures."""
        mock_embedding_service = mock.MagicMock()
        mock_embedding_service.embed_chunks.side_effect = Exception("Embedding failed")
        mock_get_embedding.return_value = mock_embedding_service

        pipeline = Pipeline(data_dir=self.data_dir)

        chunks = [
            {"id": "1", "content": "Test content 1"},
            {"id": "2", "content": "Test content 2"},
        ]

        result = pipeline.embed_chunks(chunks)
>       self.assertEqual(
            result,
            chunks,
            "Should return original chunks without embeddings on failure",
        )
E       AssertionError: Lists differ: [{'id[30 chars]nt 1', 'embedding': array([-6.45101210e-03, -6[14470 chars]32)}] != [{'id[30 chars]nt 1'}, {'id': '2', 'content': 'Test content 2'}]
E
E       First differing element 0:
E       {'id'[29 chars]nt 1', 'embedding': array([-6.45101210e-03, -6[7191 chars]t32)}
E       {'id'[29 chars]nt 1'}
E
E       Diff is 15144 characters long. Set self.maxDiff to None to see it. : Should return original chunks without embeddings on failure

tests/unit/test_pipeline_edge_cases.py:104: AssertionError
___________________________________________________________________________________________________ TestPipelineEdgeCases.test_invalid_chunking_strategy ___________________________________________________________________________________________________

self = <tests.unit.test_pipeline_edge_cases.TestPipelineEdgeCases testMethod=test_invalid_chunking_strategy>

    def test_invalid_chunking_strategy(self):
        """Test handling of invalid chunking strategy."""
        doc = {
            "url": "https://example.com",
            "content": "# Test\nSome content for testing.",
            "title": "Test Document",
        }

        with mock.patch("RAGnificent.core.config.get_config") as mock_config:
            mock_config.return_value.chunking.strategy = "invalid_strategy"
            chunks = self.pipeline.chunk_documents([doc])
>           self.assertEqual(
                len(chunks), 0, "Invalid chunking strategy should yield no chunks"
            )
E           AssertionError: 1 != 0 : Invalid chunking strategy should yield no chunks

tests/unit/test_pipeline_edge_cases.py:85: AssertionError
______________________________________________________________________________________________________ TestPipelineEdgeCases.test_malformed_document _______________________________________________________________________________________________________

self = <tests.unit.test_pipeline_edge_cases.TestPipelineEdgeCases testMethod=test_malformed_document>

    def test_malformed_document(self):
        """Test handling of malformed documents."""
        malformed_docs = [
            {"url": "https://example.com"},  # Missing content
            {"content": "Some content"},  # Missing URL
            {},  # Empty document
        ]

        chunks = self.pipeline.chunk_documents(malformed_docs)
>       self.assertEqual(len(chunks), 0, "Malformed documents should yield no chunks")
E       AssertionError: 1 != 0 : Malformed documents should yield no chunks

tests/unit/test_pipeline_edge_cases.py:72: AssertionError
_______________________________________________________________________________________________ TestPipelineEdgeCasesPart2.test_query_with_context_no_openai _______________________________________________________________________________________________

self = <tests.unit.test_pipeline_edge_cases_part2.TestPipelineEdgeCasesPart2 testMethod=test_query_with_context_no_openai>

    def test_query_with_context_no_openai(self):
        """Test query_with_context when OpenAI is not available."""
        with mock.patch.dict("sys.modules", {"openai": None}):
            result = self.pipeline.query_with_context("test query")
            self.assertFalse(
                result["has_context"],
                "Should indicate no context when OpenAI is not available",
            )
>           self.assertIn("Error", result["response"], "Response should indicate error")
E           AssertionError: 'Error' not found in "I couldn't find any relevant information to answer your query." : Response should indicate error

tests/unit/test_pipeline_edge_cases_part2.py:109: AssertionError
-------------------------------------------------------------------------------------------------------------------- Captured log call ---------------------------------------------------------------------------------------------------------------------
WARNING  RAGnificent.rag.pipeline:pipeline.py:769 No relevant documents found for query: test query
_____________________________________________________________________________________________ TestScraperErrorHandling.test_parallel_processing_error_handling _____________________________________________________________________________________________

self = <tests.unit.test_scraper_error_handling.TestScraperErrorHandling testMethod=test_parallel_processing_error_handling>

    @responses.activate
    def test_parallel_processing_error_handling(self):
        """Test error handling with parallel processing."""
        print("\\n[DEBUG] Starting test_parallel_processing_error_handling")
        # Create output directory
        os.makedirs(self.output_dir, exist_ok=True)
        print(f"[DEBUG] Output directory: {self.output_dir}")

        # Create a links file
        links_file = os.path.join(self.temp_dir, "links.txt")
        with open(links_file, "w") as f:
            f.write("https://example.com/good\nhttps://example.com/bad\n")
        print(f"[DEBUG] Links file created: {links_file}")

        # Mock responses for the URLs
        responses.add(
            responses.GET,
            "https://example.com/good",
            body="<html><body><h1>Good Page</h1><p>Content</p></body></html>",
            status=200,
            content_type="text/html",
        )
        responses.add(responses.GET, "https://example.com/bad", status=500)
        print("[DEBUG] Mock responses added for /good (200) and /bad (500)")

        self.scraper.max_retries = 1  # Speed up test

        # --- Test Sequential Execution First ---
        print("\\n[DEBUG] Testing sequential execution...")
        try:
            sequential_result = self.scraper.scrape_by_links_file(
                links_file=links_file,
                output_dir=self.output_dir,
                parallel=False, # Run sequentially
            )
            print(f"[DEBUG] Sequential execution result: {sequential_result}")
            self.assertEqual(len(sequential_result), 1, "Sequential processing should yield one successful URL")
            good_file_path = Path(self.output_dir) / "example.com" / "good.markdown"
>           self.assertTrue(good_file_path.exists(), "Good file should be created in sequential mode")
E           AssertionError: False is not true : Good file should be created in sequential mode

tests/unit/test_scraper_error_handling.py:248: AssertionError

During handling of the above exception, another exception occurred:

self = <tests.unit.test_scraper_error_handling.TestScraperErrorHandling testMethod=test_parallel_processing_error_handling>

    @responses.activate
    def test_parallel_processing_error_handling(self):
        """Test error handling with parallel processing."""
        print("\\n[DEBUG] Starting test_parallel_processing_error_handling")
        # Create output directory
        os.makedirs(self.output_dir, exist_ok=True)
        print(f"[DEBUG] Output directory: {self.output_dir}")

        # Create a links file
        links_file = os.path.join(self.temp_dir, "links.txt")
        with open(links_file, "w") as f:
            f.write("https://example.com/good\nhttps://example.com/bad\n")
        print(f"[DEBUG] Links file created: {links_file}")

        # Mock responses for the URLs
        responses.add(
            responses.GET,
            "https://example.com/good",
            body="<html><body><h1>Good Page</h1><p>Content</p></body></html>",
            status=200,
            content_type="text/html",
        )
        responses.add(responses.GET, "https://example.com/bad", status=500)
        print("[DEBUG] Mock responses added for /good (200) and /bad (500)")

        self.scraper.max_retries = 1  # Speed up test

        # --- Test Sequential Execution First ---
        print("\\n[DEBUG] Testing sequential execution...")
        try:
            sequential_result = self.scraper.scrape_by_links_file(
                links_file=links_file,
                output_dir=self.output_dir,
                parallel=False, # Run sequentially
            )
            print(f"[DEBUG] Sequential execution result: {sequential_result}")
            self.assertEqual(len(sequential_result), 1, "Sequential processing should yield one successful URL")
            good_file_path = Path(self.output_dir) / "example.com" / "good.markdown"
            self.assertTrue(good_file_path.exists(), "Good file should be created in sequential mode")
            print("[DEBUG] Sequential execution successful and assertions passed.")
        except Exception as e:
            print(f"[DEBUG] Error during sequential execution: {e}")
>           self.fail(f"Sequential execution failed: {e}")
E           AssertionError: Sequential execution failed: False is not true : Good file should be created in sequential mode

tests/unit/test_scraper_error_handling.py:252: AssertionError
------------------------------------------------------------------------------------------------------------------- Captured stdout call -------------------------------------------------------------------------------------------------------------------
\n[DEBUG] Starting test_parallel_processing_error_handling
[DEBUG] Output directory: /tmp/tmpbgxpe8gx/output
[DEBUG] Links file created: /tmp/tmpbgxpe8gx/links.txt
[DEBUG] Mock responses added for /good (200) and /bad (500)
\n[DEBUG] Testing sequential execution...
[DEBUG] Sequential execution result: ['https://example.com/good']
[DEBUG] Error during sequential execution: False is not true : Good file should be created in sequential mode
-------------------------------------------------------------------------------------------------------------------- Captured log call ---------------------------------------------------------------------------------------------------------------------
WARNING  markdown_scraper:scraper.py:315 HTTP error on attempt 1/1: 500 Server Error: Internal Server Error for url: https://example.com/bad
ERROR    markdown_scraper:scraper.py:319 Failed to retrieve https://example.com/bad after 1 attempts.
ERROR    markdown_scraper:scraper.py:204 Failed to scrape https://example.com/bad: 500 Server Error: Internal Server Error for url: https://example.com/bad
ERROR    markdown_scraper:scraper.py:1113 Error processing URL https://example.com/bad: 500 Server Error: Internal Server Error for url: https://example.com/bad
WARNING  markdown_scraper:scraper.py:1122 Failed to scrape 1 URLs:
WARNING  markdown_scraper:scraper.py:1126   - https://example.com/bad: 500 Server Error: Internal Server Error for url: https://example.com/bad
__________________________________________________________________________________________________ TestScraperErrorHandling.test_worker_timeout_handling ___________________________________________________________________________________________________

self = <tests.unit.test_scraper_error_handling.TestScraperErrorHandling testMethod=test_worker_timeout_handling>

    @responses.activate
    def test_worker_timeout_handling(self):
        """Test handling of worker timeouts in parallel processing."""
        # Create output directory
        os.makedirs(self.output_dir, exist_ok=True)

        # Create a links file
        links_file = os.path.join(self.temp_dir, "links.txt")
        with open(links_file, "w") as f:
            f.write("https://example.com/fast\nhttps://example.com/slow\n")

        # Mock responses for the URLs
        responses.add(
            responses.GET,
            "https://example.com/fast",
            body="<html><body><h1>Fast Page</h1><p>Content</p></body></html>",
            status=200,
            content_type="text/html",
        )

        # Mock a very slow response that will trigger timeout
        def slow_response(request):
            import time

            time.sleep(2)  # This will exceed our worker_timeout
            return (200, {}, "<html><body><h1>Slow Page</h1></body></html>")

        responses.add_callback(
            responses.GET,
            "https://example.com/slow",
            callback=slow_response,
            content_type="text/html",
        )

        # Tests with a very short worker_timeout to simulate timeouts
        with patch(
            "concurrent.futures.Future.result",
            side_effect=TimeoutError("Worker timeout"),
        ):
            result = self.scraper.scrape_by_links_file(
                links_file=links_file,
                output_dir=self.output_dir,
                parallel=True,
                max_workers=2,
                worker_timeout=1,  # Very short timeout
            )

            # Should handle worker timeouts gracefully
>           self.assertTrue(len(result) < 2, "Should handle worker timeouts")
E           AssertionError: False is not true : Should handle worker timeouts

tests/unit/test_scraper_error_handling.py:324: AssertionError
-------------------------------------------------------------------------------------------------------------------- Captured log call ---------------------------------------------------------------------------------------------------------------------
WARNING  request_throttler:throttle.py:254 Request to https://example.com/fast failed with TypeError: MarkdownScraper.scrape_by_links_file.<locals>.throttled_process() missing 1 required positional argument: 'url'. Retrying in 2.00s (1/3)
ERROR    markdown_scraper:scraper.py:1092 Error in parallel processing: Worker timeout
WARNING  markdown_scraper:scraper.py:1093 Falling back to sequential processing
WARNING  request_throttler:throttle.py:190 Domain example.com experiencing errors (2 consecutive). Backing off for 4.02s
WARNING  request_throttler:throttle.py:254 Request to https://example.com/slow failed with TypeError: MarkdownScraper.scrape_by_links_file.<locals>.throttled_process() missing 1 required positional argument: 'url'. Retrying in 2.00s (1/3)
_____________________________________________________________________________________________________ TestSearchEdgeCases.test_search_cache_expiration _____________________________________________________________________________________________________

self = <tests.unit.test_search_edge_cases.TestSearchEdgeCases testMethod=test_search_cache_expiration>

    def test_search_cache_expiration(self):
        """Test search cache expiration."""
        self.mock_vector_store.search.return_value = [
            {"id": "1", "score": 0.9, "payload": {"content": "Test content"}}
        ]

        self.mock_config.return_value.search.cache_ttl = 0.1  # 100ms

        results1 = self.search.search("test query")
        self.assertEqual(len(results1), 1, "Should return 1 result")
        self.assertEqual(
            self.mock_vector_store.search.call_count, 1, "Should call vector store once"
        )

        results2 = self.search.search("test query")
        self.assertEqual(len(results2), 1, "Should return 1 result")
        self.assertEqual(
            self.mock_vector_store.search.call_count,
            1,
            "Should still have called vector store only once",
        )

        time.sleep(0.2)

        results3 = self.search.search("test query")
        self.assertEqual(len(results3), 1, "Should return 1 result")
>       self.assertEqual(
            self.mock_vector_store.search.call_count,
            2,
            "Should call vector store again after cache expiry",
        )
E       AssertionError: 1 != 2 : Should call vector store again after cache expiry

tests/unit/test_search_edge_cases.py:108: AssertionError
===================================================================================================================== warnings summary =====================================================================================================================
.venv/lib/python3.12/site-packages/_pytest/config/__init__.py:1474
  /home/sistr/Projects/RAGnificent/.venv/lib/python3.12/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: benchmark_columns

    self._warn_or_fail_if_strict(f"Unknown config option: {key}\n")

.venv/lib/python3.12/site-packages/_pytest/config/__init__.py:1474
  /home/sistr/Projects/RAGnificent/.venv/lib/python3.12/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: benchmark_disable_gc

    self._warn_or_fail_if_strict(f"Unknown config option: {key}\n")

.venv/lib/python3.12/site-packages/_pytest/config/__init__.py:1474
  /home/sistr/Projects/RAGnificent/.venv/lib/python3.12/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: benchmark_enable

    self._warn_or_fail_if_strict(f"Unknown config option: {key}\n")

.venv/lib/python3.12/site-packages/_pytest/config/__init__.py:1474
  /home/sistr/Projects/RAGnificent/.venv/lib/python3.12/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: benchmark_group_by

    self._warn_or_fail_if_strict(f"Unknown config option: {key}\n")

.venv/lib/python3.12/site-packages/_pytest/config/__init__.py:1474
  /home/sistr/Projects/RAGnificent/.venv/lib/python3.12/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: benchmark_max_iterations

    self._warn_or_fail_if_strict(f"Unknown config option: {key}\n")

.venv/lib/python3.12/site-packages/_pytest/config/__init__.py:1474
  /home/sistr/Projects/RAGnificent/.venv/lib/python3.12/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: benchmark_max_time

    self._warn_or_fail_if_strict(f"Unknown config option: {key}\n")

.venv/lib/python3.12/site-packages/_pytest/config/__init__.py:1474
  /home/sistr/Projects/RAGnificent/.venv/lib/python3.12/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: benchmark_min_rounds

    self._warn_or_fail_if_strict(f"Unknown config option: {key}\n")

.venv/lib/python3.12/site-packages/_pytest/config/__init__.py:1474
  /home/sistr/Projects/RAGnificent/.venv/lib/python3.12/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: benchmark_min_time

    self._warn_or_fail_if_strict(f"Unknown config option: {key}\n")

.venv/lib/python3.12/site-packages/_pytest/config/__init__.py:1474
  /home/sistr/Projects/RAGnificent/.venv/lib/python3.12/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: benchmark_only

    self._warn_or_fail_if_strict(f"Unknown config option: {key}\n")

.venv/lib/python3.12/site-packages/_pytest/config/__init__.py:1474
  /home/sistr/Projects/RAGnificent/.venv/lib/python3.12/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: benchmark_save

    self._warn_or_fail_if_strict(f"Unknown config option: {key}\n")

.venv/lib/python3.12/site-packages/_pytest/config/__init__.py:1474
  /home/sistr/Projects/RAGnificent/.venv/lib/python3.12/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: benchmark_save_data

    self._warn_or_fail_if_strict(f"Unknown config option: {key}\n")

.venv/lib/python3.12/site-packages/_pytest/config/__init__.py:1474
  /home/sistr/Projects/RAGnificent/.venv/lib/python3.12/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: benchmark_skip

    self._warn_or_fail_if_strict(f"Unknown config option: {key}\n")

.venv/lib/python3.12/site-packages/_pytest/config/__init__.py:1474
  /home/sistr/Projects/RAGnificent/.venv/lib/python3.12/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: benchmark_sort

    self._warn_or_fail_if_strict(f"Unknown config option: {key}\n")

.venv/lib/python3.12/site-packages/_pytest/config/__init__.py:1474
  /home/sistr/Projects/RAGnificent/.venv/lib/python3.12/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: benchmark_timer

    self._warn_or_fail_if_strict(f"Unknown config option: {key}\n")

.venv/lib/python3.12/site-packages/_pytest/config/__init__.py:1474
  /home/sistr/Projects/RAGnificent/.venv/lib/python3.12/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: benchmark_warmup

    self._warn_or_fail_if_strict(f"Unknown config option: {key}\n")

.venv/lib/python3.12/site-packages/pydantic/fields.py:1089: 96 warnings
  /home/sistr/Projects/RAGnificent/.venv/lib/python3.12/site-packages/pydantic/fields.py:1089: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/
    warn(

tests/benchmarks/test_performance.py::test_pipeline_performance
  /home/sistr/Projects/RAGnificent/.venv/lib/python3.12/site-packages/qdrant_client/http/models/models.py:758: SyntaxWarning: invalid escape sequence '\&'
    description="Check that the field is empty, alternative syntax for `is_empty: \&quot;field_name\&quot;`",

tests/benchmarks/test_performance.py::test_pipeline_performance
  /home/sistr/Projects/RAGnificent/.venv/lib/python3.12/site-packages/qdrant_client/http/models/models.py:762: SyntaxWarning: invalid escape sequence '\&'
    description="Check that the field is null, alternative syntax for `is_null: \&quot;field_name\&quot;`",

tests/integration/test_rag_integration.py::TestRAGIntegration::test_end_to_end_pipeline
tests/unit/test_pipeline_edge_cases_part2.py::TestPipelineEdgeCasesPart2::test_query_with_context_no_openai
  /home/sistr/Projects/RAGnificent/RAGnificent/rag/vector_store.py:373: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.
    search_result = self.client.search(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html

------------------------------------------------------------------------------------------------------------------------- benchmark 'caching': 4 tests ------------------------------------------------------------------------------------------------------------------------
Name (time in ns)                                          Min                           Max                          Mean                     StdDev                        Median                       IQR            Outliers             OPS            Rounds  Iterations
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
test_benchmark_cache_get                              393.6333 (1.0)             13,767.2000 (1.0)                453.6893 (1.0)              73.1700 (1.0)                450.4000 (1.0)             14.8667 (1.0)      735;3610  2,204,151.6949 (1.0)       82258          30
test_benchmark_scrape_with_cache_enabled            2,900.0003 (7.37)            52,608.9998 (3.82)             3,590.9651 (7.92)            839.0678 (11.47)            3,563.0001 (7.91)           174.0000 (11.70)    777;4986    278,476.6707 (0.13)      32702           1
test_benchmark_cache_set                           22,539.9999 (57.26)          609,031.9994 (44.24)           27,842.1545 (61.37)        17,750.0494 (242.59)          24,661.0002 (54.75)        1,655.5000 (111.36)    159;243     35,916.7607 (0.02)       3120           1
test_benchmark_scrape_with_cache_disabled     999,257,507.0000 (>1000.0)  1,200,663,476.9996 (>1000.0)  1,030,351,717.5998 (>1000.0)  67,631,165.7429 (>1000.0)  1,000,516,670.5000 (>1000.0)  1,170,681.0001 (>1000.0)       2;2          0.9705 (0.00)         10           1
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

------------------------------------------------ benchmark 'convert_to_markdown': 1 tests ------------------------------------------------
Name (time in us)                           Min       Max      Mean   StdDev    Median     IQR  Outliers  OPS (Kops/s)  Rounds  Iterations
------------------------------------------------------------------------------------------------------------------------------------------
test_convert_to_markdown_benchmark     133.6170  902.0900  149.7366  27.9431  143.0760  8.9170    96;144        6.6784    1555           1
------------------------------------------------------------------------------------------------------------------------------------------

--------------------------------------------- benchmark 'create_chunks': 1 tests --------------------------------------------
Name (time in us)                   Min       Max    Mean  StdDev  Median     IQR  Outliers  OPS (Kops/s)  Rounds  Iterations
-----------------------------------------------------------------------------------------------------------------------------
test_create_chunks_benchmark     4.9610  197.1440  5.5934  1.9903  5.4920  0.2400    97;388      178.7821   10207           1
-----------------------------------------------------------------------------------------------------------------------------

------------------------------------------------ benchmark 'save_chunks': 1 tests -----------------------------------------------
Name (time in us)                  Min         Max     Mean   StdDev   Median     IQR  Outliers  OPS (Kops/s)  Rounds  Iterations
---------------------------------------------------------------------------------------------------------------------------------
test_save_chunks_benchmark     23.2320  4,897.5360  26.0443  46.8498  25.2610  0.8730     2;712       38.3961   10858           1
---------------------------------------------------------------------------------------------------------------------------------

---------------------------------------------- benchmark 'save_markdown': 1 tests ----------------------------------------------
Name (time in us)                    Min       Max     Mean  StdDev   Median     IQR  Outliers  OPS (Kops/s)  Rounds  Iterations
--------------------------------------------------------------------------------------------------------------------------------
test_save_markdown_benchmark     10.6390  186.3420  11.8157  1.6768  11.4740  0.9900   663;552       84.6334   24986           1
--------------------------------------------------------------------------------------------------------------------------------

-------------------------------------------- benchmark 'scrape_website': 1 tests --------------------------------------------
Name (time in us)                    Min      Max    Mean  StdDev  Median     IQR  Outliers  OPS (Kops/s)  Rounds  Iterations
-----------------------------------------------------------------------------------------------------------------------------
test_scrape_website_benchmark     3.0880  13.8470  4.0056  2.4307  3.2105  0.3465       1;4      249.6536      20           1
-----------------------------------------------------------------------------------------------------------------------------

Legend:
  Outliers: 1 Standard Deviation from Mean; 1.5 IQR (InterQuartile Range) from 1st Quartile and 3rd Quartile.
  OPS: Operations Per Second, computed as 1 / Mean
================================================================================================================= short test summary info ==================================================================================================================
FAILED tests/benchmarks/test_performance.py::test_throttler_performance - TypeError: test_throttler_performance.<locals>.mock_request() missing 1 required positional argument: 'url'
FAILED tests/benchmarks/test_performance.py::test_chunker_performance - TypeError: ContentChunker.create_chunks_from_markdown() missing 1 required positional argument: 'source_url'
FAILED tests/benchmarks/test_performance.py::test_pipeline_performance - TypeError: mock_vector_store.<locals>.MockVectorStore.store_documents() got an unexpected keyword argument 'embedding_field'
FAILED tests/benchmarks/test_performance.py::test_parallel_scraping_performance - TypeError: MarkdownScraper.scrape_by_sitemap() missing 1 required positional argument: 'output_dir'
FAILED tests/integration/test_rag_integration.py::TestRAGIntegration::test_end_to_end_pipeline - AssertionError: 0 not greater than 0 : Should find results for query
FAILED tests/unit/test_config.py::TestConfigFileSupport::test_app_config_initialization_with_dict_override - AttributeError: type object 'ChunkingStrategy' has no attribute 'SENTENCE'
FAILED tests/unit/test_embedding_edge_cases_part2.py::TestEmbeddingEdgeCasesPart2::test_openai_api_error - AttributeError: <module 'RAGnificent.rag.embedding' from '/home/sistr/Projects/RAGnificent/RAGnificent/rag/embedding.py'> does not have the attribute 'openai'
FAILED tests/unit/test_embedding_edge_cases_part2.py::TestEmbeddingEdgeCasesPart2::test_openai_retry_logic - AttributeError: <module 'RAGnificent.rag.embedding' from '/home/sistr/Projects/RAGnificent/RAGnificent/rag/embedding.py'> does not have the attribute 'openai'
FAILED tests/unit/test_embedding_edge_cases_part2.py::TestEmbeddingEdgeCasesPart2::test_sentence_transformer_embedding_error - AttributeError: <module 'RAGnificent.rag.embedding' from '/home/sistr/Projects/RAGnificent/RAGnificent/rag/embedding.py'> does not have the attribute 'SentenceTransformer'
FAILED tests/unit/test_embedding_edge_cases_part2.py::TestEmbeddingEdgeCasesPart2::test_sentence_transformer_import_error - AttributeError: <module 'RAGnificent.rag.embedding' from '/home/sistr/Projects/RAGnificent/RAGnificent/rag/embedding.py'> does not have the attribute 'SentenceTransformer'
FAILED tests/unit/test_embedding_edge_cases_part2.py::TestEmbeddingEdgeCasesPart2::test_sentence_transformer_model_error - AttributeError: <module 'RAGnificent.rag.embedding' from '/home/sistr/Projects/RAGnificent/RAGnificent/rag/embedding.py'> does not have the attribute 'SentenceTransformer'
FAILED tests/unit/test_nested_headers/fixed_test.py::TestNestedHeaderChunking::test_nested_header_chunking - AssertionError: 0 not greater than 0 : Should have chunks for Nested Subtopic 1.1
FAILED tests/unit/test_nested_headers/test_improved_chunking.py::TestImprovedNestedHeaderChunking::test_nested_header_chunking - AssertionError: 0 not greater than 0 : Should have chunks for Nested Subtopic 1.1
FAILED tests/unit/test_nested_headers/test_improved_chunking.py::TestImprovedNestedHeaderChunking::test_section_parsing - AssertionError: 1 not greater than or equal to 5 : Should find at least 5 sections
FAILED tests/unit/test_nested_headers/test_nested_header_chunking.py::TestNestedHeaderChunking::test_nested_header_chunking - AssertionError: 0 not greater than 0 : Should have chunks for Nested Subtopic 1.1
FAILED tests/unit/test_pipeline_edge_cases.py::TestPipelineEdgeCases::test_embedding_failure - AssertionError: Lists differ: [{'id[30 chars]nt 1', 'embedding': array([-6.45101210e-03, -6[14470 chars]32)}] != [{'id[30 chars]nt 1'}, {'id': '2', 'content': 'Test content 2'}]
FAILED tests/unit/test_pipeline_edge_cases.py::TestPipelineEdgeCases::test_invalid_chunking_strategy - AssertionError: 1 != 0 : Invalid chunking strategy should yield no chunks
FAILED tests/unit/test_pipeline_edge_cases.py::TestPipelineEdgeCases::test_malformed_document - AssertionError: 1 != 0 : Malformed documents should yield no chunks
FAILED tests/unit/test_pipeline_edge_cases_part2.py::TestPipelineEdgeCasesPart2::test_query_with_context_no_openai - AssertionError: 'Error' not found in "I couldn't find any relevant information to answer your query." : Response should indicate error
FAILED tests/unit/test_scraper_error_handling.py::TestScraperErrorHandling::test_parallel_processing_error_handling - AssertionError: Sequential execution failed: False is not true : Good file should be created in sequential mode
FAILED tests/unit/test_scraper_error_handling.py::TestScraperErrorHandling::test_worker_timeout_handling - AssertionError: False is not true : Should handle worker timeouts
FAILED tests/unit/test_search_edge_cases.py::TestSearchEdgeCases::test_search_cache_expiration - AssertionError: 1 != 2 : Should call vector store again after cache expiry
============================================================================================ 22 failed, 91 passed, 8 skipped, 115 warnings in 190.07s (0:03:10) ============================================================================================
Domain example.com experiencing errors (6 consecutive). Backing off for 67.88s
Request to https://example.com/slow failed with TypeError: MarkdownScraper.scrape_by_links_file.<locals>.throttled_process() missing 1 required positional argument: 'url'. Retrying in 8.00s (3/3)
